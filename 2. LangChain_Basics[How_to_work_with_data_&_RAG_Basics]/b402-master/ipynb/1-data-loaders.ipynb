{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **1-data-loaders**\n",
        "\n",
        "## **🤖 Introduction**\n",
        "- **Data Loaders**: Tools that let you **load all kinds of data**—documents, PDFs, web pages—so you can query them with an LLM.\n",
        "- **Connect** to private data sources or local files, turning them into a format the LLM can work with.\n",
        "- **LangChain Built-In Loaders**: Often labeled as **\"integrations\"**; each loader may require specific libraries (e.g., `PyPDF2`, `docx`, `BeautifulSoup`).\n",
        "- For more details, see the **LangChain documentation on Document Loaders**:\n",
        "  - **Documentation Page**: Explains usage patterns and advanced tips.\n",
        "  - **List of Built-In Loaders**: Shows which libraries you need for each file or data type.\n",
        "\n",
        "---\n",
        "\n",
        "## **⚙️ Setup**\n",
        "1. **Clone or Download** the GitHub repository to your computer.\n",
        "2. In **terminal**:\n",
        "   ```\n",
        "   cd project_name\n",
        "   pyenv local 3.11.4\n",
        "   poetry install\n",
        "   poetry shell\n",
        "   ```\n",
        "3. Launch **Jupyter Lab**:\n",
        "   ```\n",
        "   jupyter lab\n",
        "   ```\n",
        "   - Open the `001-data-loaders.ipynb` notebook in your notebooks folder.\n",
        "4. **View Code** in an editor like VS Code:\n",
        "   - Locate and open `001-data-loaders.py`.\n",
        "\n",
        "---\n",
        "\n",
        "## **🔐 Create Your `.env` File**\n",
        "- **`.env.example`** is provided; rename it to **`.env`**.\n",
        "- Add the following keys:\n",
        "  ```\n",
        "  OPENAI_API_KEY=your_openai_api_key\n",
        "  LANGCHAIN_TRACING_V2=true\n",
        "  LANGCHAIN_ENDPOINT=https://api.smith.langchain.com\n",
        "  LANGCHAIN_API_KEY=your_langchain_api_key\n",
        "  LANGCHAIN_PROJECT=your_project_name\n",
        "  ```\n",
        "- This project is **`001-data-loaders`** in **LangSmith**.\n",
        "\n",
        "---\n",
        "\n",
        "## **📊 Track Operations**\n",
        "- **Monitor** usage and costs in **LangSmith**:\n",
        "  ```\n",
        "  smith.langchain.com\n",
        "  ```\n",
        "\n",
        "> **💡 Note**: Data loaders can drastically simplify your workflow by **standardizing** how data is read, parsed, and fed into the LLM for further processing or question-answering.\n"
      ],
      "metadata": {
        "id": "GihAXkRfLHvV"
      },
      "id": "GihAXkRfLHvV"
    },
    {
      "cell_type": "markdown",
      "id": "5a2f9501-fa9e-4830-95e2-537dff951cf1",
      "metadata": {
        "id": "5a2f9501-fa9e-4830-95e2-537dff951cf1"
      },
      "source": [
        "## LangChain documentation on Document Loaders\n",
        "* See the documentation page [here](https://python.langchain.com/v0.1/docs/modules/data_connection/document_loaders/).\n",
        "* See the list of built-in document loaders [here](https://python.langchain.com/v0.1/docs/integrations/document_loaders/)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f99504a-1b8f-4360-b342-0b81ffa06aff",
      "metadata": {
        "id": "4f99504a-1b8f-4360-b342-0b81ffa06aff"
      },
      "source": [
        "## Connect with the .env file located in the same directory of this notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e39e5789-5bde-42e1-88dd-92dc8e363c24",
      "metadata": {
        "id": "e39e5789-5bde-42e1-88dd-92dc8e363c24"
      },
      "source": [
        "If you are using the pre-loaded poetry shell, you do not need to install the following package because it is already pre-loaded for you:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5514113-ddca-4ae9-9de6-0b9225b18f3c",
      "metadata": {
        "id": "c5514113-ddca-4ae9-9de6-0b9225b18f3c"
      },
      "outputs": [],
      "source": [
        "#pip install python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fecd39d0-e72e-4bc2-8a68-2fa4008ea365",
      "metadata": {
        "id": "fecd39d0-e72e-4bc2-8a68-2fa4008ea365"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "_ = load_dotenv(find_dotenv())\n",
        "openai_api_key = os.environ[\"OPENAI_API_KEY\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03f4a923-b19e-498e-9be5-e47ec4a77d80",
      "metadata": {
        "id": "03f4a923-b19e-498e-9be5-e47ec4a77d80"
      },
      "source": [
        "#### Install LangChain"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9fef1e5c-b7e2-4a04-96c5-8f64377b8eba",
      "metadata": {
        "id": "9fef1e5c-b7e2-4a04-96c5-8f64377b8eba"
      },
      "source": [
        "If you are using the pre-loaded poetry shell, you do not need to install the following package because it is already pre-loaded for you:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1cf94ae-6c39-4475-9c5b-4b74d8d78753",
      "metadata": {
        "id": "c1cf94ae-6c39-4475-9c5b-4b74d8d78753"
      },
      "outputs": [],
      "source": [
        "#!pip install langchain"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "189e9e17-dfb0-4fd3-85b9-1fba83771941",
      "metadata": {
        "id": "189e9e17-dfb0-4fd3-85b9-1fba83771941"
      },
      "source": [
        "## Connect with an LLM"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b21d23f4-61f5-4227-8a75-7eefde6680ee",
      "metadata": {
        "id": "b21d23f4-61f5-4227-8a75-7eefde6680ee"
      },
      "source": [
        "If you are using the pre-loaded poetry shell, you do not need to install the following package because it is already pre-loaded for you:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "148df8e0-361d-4ddd-8709-af48fa1648d1",
      "metadata": {
        "id": "148df8e0-361d-4ddd-8709-af48fa1648d1"
      },
      "outputs": [],
      "source": [
        "#!pip install langchain-openai"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1998155-91de-4cbc-bc88-8d77beefb51b",
      "metadata": {
        "id": "a1998155-91de-4cbc-bc88-8d77beefb51b"
      },
      "source": [
        "* NOTE: Since right now is the best LLM in the market, we will use OpenAI by default. You will see how to connect with other Open Source LLMs like Llama3 or Mistral in a next lesson."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f639b09-de0e-43ff-826c-03deb85605b9",
      "metadata": {
        "id": "3f639b09-de0e-43ff-826c-03deb85605b9"
      },
      "source": [
        "## Simple data loading"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17c5afd8-9c16-4d5e-97da-4c59f1460b15",
      "metadata": {
        "id": "17c5afd8-9c16-4d5e-97da-4c59f1460b15"
      },
      "source": [
        "#### Loading a .txt file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b14d27c3-0b1b-4b11-a883-8da2734f21a7",
      "metadata": {
        "id": "b14d27c3-0b1b-4b11-a883-8da2734f21a7"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "chatModel = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4cafba46-3c43-457e-9a9a-19978f4fdab9",
      "metadata": {
        "id": "4cafba46-3c43-457e-9a9a-19978f4fdab9"
      },
      "source": [
        "If you are using the pre-loaded poetry shell, you do not need to install the following package because it is already pre-loaded for you:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2175d878-2274-4852-ae62-b3b9f704f31c",
      "metadata": {
        "id": "2175d878-2274-4852-ae62-b3b9f704f31c"
      },
      "outputs": [],
      "source": [
        "#!pip install langchain-community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "438c93f3-a1ff-41de-af09-bc67729ad271",
      "metadata": {
        "id": "438c93f3-a1ff-41de-af09-bc67729ad271"
      },
      "outputs": [],
      "source": [
        "# Import the TextLoader class from the community document loaders\n",
        "from langchain_community.document_loaders import TextLoader\n",
        "\n",
        "# Create a TextLoader instance, pointing to a local text file\n",
        "loader = TextLoader(\"./data/be-good.txt\")\n",
        "\n",
        "# Load the data from the specified file into a structured format\n",
        "loaded_data = loader.load()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **⚙️ How This Works**\n",
        "- **TextLoader** reads plain text files and converts them into a **standardized** LangChain document format.\n",
        "- By pointing it to `\"./data/be-good.txt\"`, you can **easily** incorporate the file’s content into your workflow—such as Q&A, summarization, or chaining tasks.\n",
        "\n",
        "### **💼 Why Use a Document Loader?**\n",
        "- **Consistency**: Ensures each document is represented with consistent metadata (e.g., source, page numbers).\n",
        "- **Scalability**: Makes it simpler to add more loaders for **different** file types (PDF, CSV, HTML).\n",
        "- **Modularity**: Keep your data ingestion separate from your LLM logic, making code more maintainable.\n",
        "\n",
        "> **🔎 Pro Tip**: After loading, you can pass `loaded_data` to various **LangChain** components (like text splitters, vector stores, or prompt templates) to build sophisticated applications.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1WhtF6-pLYn8"
      },
      "id": "1WhtF6-pLYn8"
    },
    {
      "cell_type": "markdown",
      "id": "daa0d08b-8ae6-4276-b2c1-70c0cd8d8bde",
      "metadata": {
        "id": "daa0d08b-8ae6-4276-b2c1-70c0cd8d8bde"
      },
      "source": [
        "* If you uncomment and execute the next cell you will see the contents of the loaded document."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e6bc045-56d3-4e1d-b822-85c40a2e9609",
      "metadata": {
        "id": "8e6bc045-56d3-4e1d-b822-85c40a2e9609"
      },
      "outputs": [],
      "source": [
        "#loaded_data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b39dc7c6-3386-43ff-a0a6-c3abe54897c5",
      "metadata": {
        "id": "b39dc7c6-3386-43ff-a0a6-c3abe54897c5"
      },
      "source": [
        "# **Loading a CSV file**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4fa559db-8f5a-4ffd-a9c2-541f6099c8cd",
      "metadata": {
        "id": "4fa559db-8f5a-4ffd-a9c2-541f6099c8cd"
      },
      "outputs": [],
      "source": [
        "# Import CSVLoader from the community document loaders\n",
        "from langchain_community.document_loaders import CSVLoader\n",
        "\n",
        "# Instantiate the loader with a path to the CSV file\n",
        "loader = CSVLoader('./data/Street_Tree_List.csv')\n",
        "\n",
        "# Load the CSV file data into a structured LangChain format\n",
        "loaded_data = loader.load()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **⚙️ How Does CSVLoader Work?**  \n",
        "- **🔍 Reads CSV**: The loader scans each row, converting it into a format that LangChain can understand—usually a list of documents or records.  \n",
        "- **🗄 Data Organization**: Each row can become its own “document,” complete with any metadata you might need (like column headers).  \n",
        "- **♻️ Reusability**: If you have multiple CSV files, you can apply the same loader logic to each, keeping your code consistent.\n",
        "\n",
        "### **💼 Why Use a Document Loader for CSV?**\n",
        "- **Standardization**: Ensures the data is uniformly structured for subsequent LLM tasks (like Q&A or summarization).  \n",
        "- **Scalability**: Makes it easy to load large or multiple CSVs without manually parsing them.  \n",
        "- **Integration**: Once loaded, you can feed `loaded_data` into other LangChain components—like text splitters, vector stores, or prompt templates.\n",
        "\n",
        "> **💡 Pro Tip**: Pair CSVLoader with a text splitter if you have lengthy cell data. This helps the LLM handle the content more effectively during downstream tasks.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SW8UHNU1L9SS"
      },
      "id": "SW8UHNU1L9SS"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "864441c6-4a4c-4b38-ab38-f51517b2af45",
      "metadata": {
        "id": "864441c6-4a4c-4b38-ab38-f51517b2af45"
      },
      "outputs": [],
      "source": [
        "#loaded_data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cfb26c9d-0813-4877-846d-ea022a345709",
      "metadata": {
        "id": "cfb26c9d-0813-4877-846d-ea022a345709"
      },
      "source": [
        "# **Loading an .html file**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ce0455f-d8ae-43a8-9e19-de45bd623393",
      "metadata": {
        "id": "5ce0455f-d8ae-43a8-9e19-de45bd623393"
      },
      "source": [
        "If you are using the pre-loaded poetry shell, you do not need to install the following package because it is already pre-loaded for you:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74cf0ae9-8f7f-484e-b2d2-cc8db2c9f4e8",
      "metadata": {
        "id": "74cf0ae9-8f7f-484e-b2d2-cc8db2c9f4e8"
      },
      "outputs": [],
      "source": [
        "#!pip install bs4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b62f5922-747d-48e3-94d3-319cb0fbb96c",
      "metadata": {
        "id": "b62f5922-747d-48e3-94d3-319cb0fbb96c"
      },
      "outputs": [],
      "source": [
        "# Import the UnstructuredHTMLLoader for parsing HTML files\n",
        "from langchain_community.document_loaders import UnstructuredHTMLLoader\n",
        "\n",
        "# Instantiate the loader, pointing to an HTML file named '100-startups.html'\n",
        "loader = UnstructuredHTMLLoader('./data/100-startups.html')\n",
        "\n",
        "# Load the HTML data, converting it into a LangChain-compatible document format\n",
        "loaded_data = loader.load()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **🔍 Line-by-Line Analysis**\n",
        "1. **`from langchain_community.document_loaders import UnstructuredHTMLLoader`**  \n",
        "   - Imports the **UnstructuredHTMLLoader**, a specialized loader that extracts text and metadata from HTML documents.\n",
        "\n",
        "2. **`loader = UnstructuredHTMLLoader('./data/100-startups.html')`**  \n",
        "   - Creates an instance of **UnstructuredHTMLLoader**, pointing to the **`100-startups.html`** file in the `./data` folder.  \n",
        "   - Under the hood, it leverages unstructured parsing methods to **cleanly** extract text from HTML tags, discarding extraneous markup.\n",
        "\n",
        "3. **`loaded_data = loader.load()`**  \n",
        "   - Executes the loading process, returning a list (or similar structure) of LangChain **Documents**.  \n",
        "   - Each document typically contains:  \n",
        "     - **Text**: The main textual content from the HTML file.  \n",
        "     - **Metadata**: Possibly includes source info, document creation time, or extracted metadata from `<title>` or `<meta>` tags.\n",
        "\n",
        "### **💼 Why Use `UnstructuredHTMLLoader`?**\n",
        "- **Comprehensive Parsing**: It can handle various HTML layouts, ignoring scripts and styling to focus on **readable** text.  \n",
        "- **Format Uniformity**: Converts HTML content into a **standard** LangChain document format, simplifying subsequent LLM tasks like summarization or question-answering.  \n",
        "- **Scalability**: You can easily process multiple HTML files with consistent parsing rules.\n",
        "\n",
        "### **🤖 Common Next Steps**\n",
        "- **Indexing**: Store the extracted text in a vector database for **semantic search** or chat-based retrieval.  \n",
        "- **Text Splitting**: If the HTML is lengthy, break the content into **manageable** chunks before passing it to an LLM.  \n",
        "- **Chaining**: Combine these documents with other data loaders (e.g., PDFs, CSVs) to build a **unified** knowledge base for your LLM.\n",
        "\n",
        "> **💡 Pro Tip**: If your HTML files have **complex** structures, consider customizing the parser settings or pre-processing the HTML to remove non-relevant sections (like ads or navigation menus). This ensures cleaner data for your LLM pipeline."
      ],
      "metadata": {
        "id": "cb5Yx22jMtry"
      },
      "id": "cb5Yx22jMtry"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac9b265a-4b91-420a-a9c1-b9f352095458",
      "metadata": {
        "id": "ac9b265a-4b91-420a-a9c1-b9f352095458"
      },
      "outputs": [],
      "source": [
        "#loaded_data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9612386a-60df-4e83-9804-a4f0a6b4086e",
      "metadata": {
        "id": "9612386a-60df-4e83-9804-a4f0a6b4086e"
      },
      "source": [
        "# **Loading a .pdf file**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b5a3725-07af-4be0-a6f0-fe6271a8e060",
      "metadata": {
        "id": "6b5a3725-07af-4be0-a6f0-fe6271a8e060"
      },
      "source": [
        "If you are using the pre-loaded poetry shell, you do not need to install the following package because it is already pre-loaded for you:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "587e4158-d2f3-423f-a481-438aa0822432",
      "metadata": {
        "id": "587e4158-d2f3-423f-a481-438aa0822432"
      },
      "outputs": [],
      "source": [
        "#!pip install pypdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb50f45f-e6b7-4623-84d5-d121e33a4387",
      "metadata": {
        "id": "fb50f45f-e6b7-4623-84d5-d121e33a4387"
      },
      "outputs": [],
      "source": [
        "# Import the PyPDFLoader from the community document loaders\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "# Create a loader for the specified PDF file\n",
        "loader = PyPDFLoader('./data/5pages.pdf')\n",
        "\n",
        "# Load the PDF and split its content into smaller segments\n",
        "loaded_data = loader.load_and_split()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **🔎 What’s Happening?**\n",
        "1. **`PyPDFLoader('./data/5pages.pdf')`**  \n",
        "   - **Loads** the file named **`5pages.pdf`** from the `./data` folder.  \n",
        "   - Under the hood, PyPDFLoader leverages **PyPDF2** or a similar library to read PDF pages.\n",
        "\n",
        "2. **`loader.load_and_split()`**  \n",
        "   - **Retrieves** the PDF’s textual content and **splits** it into smaller chunks.  \n",
        "   - This is especially useful for **LLM** tasks, where dealing with large text blocks can lead to token limits or less coherent outputs.\n",
        "\n",
        "### **🤖 Why Use `PyPDFLoader`?**\n",
        "- **Streamlined Workflow**: Automates reading PDFs, saving you from manual parsing.  \n",
        "- **Consistent Output**: Produces standardized LangChain “document” objects that can be indexed, embedded, or queried.  \n",
        "- **Scalability**: Works on multi-page PDFs, ensuring each page (or chunk) is treated separately for more efficient **Q&A** or summarization.\n",
        "\n",
        "### **💡 Key Benefits**\n",
        "- **Chunked Documents**: Breaking large PDFs into smaller segments helps the LLM handle content more accurately.  \n",
        "- **Metadata Preservation**: The loader often retains page numbers or other relevant info, aiding in references or citations.  \n",
        "- **Versatility**: Combine with other loaders (HTML, CSV, text) for a **multi-source** pipeline.\n",
        "\n",
        "> **✨ Pro Tip**: If your PDF is **very** large or has complex formatting (tables, footnotes), consider **additional** text-splitting or data-cleaning steps for best results."
      ],
      "metadata": {
        "id": "NhpepCN4VWXq"
      },
      "id": "NhpepCN4VWXq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca3c2412-1de3-4224-ac11-21765dc2e723",
      "metadata": {
        "id": "ca3c2412-1de3-4224-ac11-21765dc2e723"
      },
      "outputs": [],
      "source": [
        "#loaded_data[0].page_content"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b168178e-7730-4427-b43c-4e2321d216d7",
      "metadata": {
        "id": "b168178e-7730-4427-b43c-4e2321d216d7"
      },
      "source": [
        "# **Loading a Wikipedia page and asking questions about it**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a570d68-31b4-448e-bc93-948df3092223",
      "metadata": {
        "id": "9a570d68-31b4-448e-bc93-948df3092223"
      },
      "source": [
        "If you are using the pre-loaded poetry shell, you do not need to install the following package because it is already pre-loaded for you:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6b67dd6-19d6-4b15-a153-12b5297cffa6",
      "metadata": {
        "id": "b6b67dd6-19d6-4b15-a153-12b5297cffa6"
      },
      "outputs": [],
      "source": [
        "#!pip install wikipedia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4af0a00-1afa-456e-951d-15fe8ba2c763",
      "metadata": {
        "id": "c4af0a00-1afa-456e-951d-15fe8ba2c763"
      },
      "outputs": [],
      "source": [
        "# Import WikipediaLoader from the community document loaders\n",
        "from langchain_community.document_loaders import WikipediaLoader\n",
        "\n",
        "# Define the search query for Wikipedia\n",
        "name = \"JFK\"\n",
        "\n",
        "# Create a loader that fetches up to 1 document matching the query\n",
        "loader = WikipediaLoader(query=name, load_max_docs=1)\n",
        "\n",
        "# Load the data and extract the 'page_content' from the first result\n",
        "loaded_data = loader.load()[0].page_content"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **🔎 Line-by-Line Breakdown**\n",
        "1. **`from langchain_community.document_loaders import WikipediaLoader`**  \n",
        "   - **⚙️** Imports a specialized loader that queries Wikipedia and returns matching articles in a LangChain-compatible format.\n",
        "\n",
        "2. **`name = \"JFK\"`**  \n",
        "   - **📝** Specifies the **search term** (“JFK”), which the loader will use to find relevant Wikipedia entries.\n",
        "\n",
        "3. **`loader = WikipediaLoader(query=name, load_max_docs=1)`**  \n",
        "   - **🔍** Initializes the loader with the query (`\"JFK\"`) and limits results to **1 document**.  \n",
        "   - **Why a limit?** Avoids pulling multiple pages if you only need a single reference.\n",
        "\n",
        "4. **`loaded_data = loader.load()[0].page_content`**  \n",
        "   - **📥** Calls `.load()` to perform the Wikipedia search and retrieval.  \n",
        "   - **[0].page_content** selects the first document from the list of results and extracts its **text content**.  \n",
        "   - You can now **store**, **summarize**, or **query** this text using LangChain or other LLM-based methods.\n",
        "\n",
        "### **💡 Why Use `WikipediaLoader`?**\n",
        "- **Immediate Access**: Instantly fetch up-to-date encyclopedia entries without manual copying.  \n",
        "- **Structured Output**: Integrates seamlessly with LangChain, enabling Q&A or summarization pipelines.  \n",
        "- **Customizable**: Adjust `load_max_docs` to fetch more articles or refine your query for specific topics.\n",
        "\n",
        "> **🤖 Pro Tip**: After retrieving `page_content`, consider splitting or chunking the text for better performance in LLM tasks (especially if the article is very long)."
      ],
      "metadata": {
        "id": "JXSmAzrJVsHo"
      },
      "id": "JXSmAzrJVsHo"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74c6b0be-9dd0-43b9-bd3e-d0a551987998",
      "metadata": {
        "id": "74c6b0be-9dd0-43b9-bd3e-d0a551987998"
      },
      "outputs": [],
      "source": [
        "# Import the ChatPromptTemplate class to build a chat-style prompt\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "# Create a chat prompt with placeholders for 'question' and 'context'\n",
        "chat_template = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"human\", \"Answer this {question}, here is some extra {context}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Format the messages by substituting the actual question and the loaded data\n",
        "messages = chat_template.format_messages(\n",
        "    question=\"What was the full name of JFK\",\n",
        "    context=loaded_data\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **🔎 What’s Happening?**\n",
        "1. **Prompt Definition**  \n",
        "   - **`ChatPromptTemplate.from_messages(...)`**: Defines a single **human** message containing two placeholders:\n",
        "     - **`{question}`**: The query the user wants answered (e.g., “What was the full name of JFK?”).  \n",
        "     - **`{context}`**: Extra information or text (in this case, `loaded_data` from Wikipedia about JFK).\n",
        "\n",
        "2. **Placeholder Substitution**  \n",
        "   - **`chat_template.format_messages(...)`**: Replaces the placeholders with the actual values (`\"What was the full name of JFK\"` and the text in `loaded_data`).  \n",
        "   - Produces a **message list** ready to be passed to an LLM or chain.\n",
        "\n",
        "3. **Relevance of `loaded_data`**  \n",
        "   - **`loaded_data`** presumably contains a Wikipedia entry or other relevant text about JFK.  \n",
        "   - By injecting it into the prompt, you give the LLM **context** that it can reference to craft an accurate answer.\n",
        "\n",
        "### **🤔 Why This Matters?**\n",
        "- **Context Injection**: Providing background info alongside the question helps the LLM answer more precisely.  \n",
        "- **Modular Design**: You can easily **swap** `question` or `context` to address different topics or data sources without rewriting the prompt logic.  \n",
        "- **Scalability**: In a larger application, you might load multiple documents or even do a semantic search first, then feed the best result as `context`.\n",
        "\n",
        "> **💡 Pro Tip**: If the `loaded_data` is lengthy, consider **text splitting** or summarizing it before injecting it into the prompt. This helps the LLM handle the data more efficiently and avoids hitting token limits."
      ],
      "metadata": {
        "id": "sUqKm_q1V_J3"
      },
      "id": "sUqKm_q1V_J3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e618700d-8a5a-4837-adbe-818f3d639497",
      "metadata": {
        "id": "e618700d-8a5a-4837-adbe-818f3d639497"
      },
      "outputs": [],
      "source": [
        "response = chatModel.invoke(messages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85bd5fa3",
      "metadata": {
        "id": "85bd5fa3"
      },
      "outputs": [],
      "source": [
        "response"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dbc24f4f-d23c-4202-992d-91b0623136ae",
      "metadata": {
        "id": "dbc24f4f-d23c-4202-992d-91b0623136ae"
      },
      "source": [
        "## How to execute the code from Visual Studio Code\n",
        "* In Visual Studio Code, see the file 001-data-loaders.py\n",
        "* In terminal, make sure you are in the directory of the file and run:\n",
        "    * python 001-data-loaders.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1af248e-6069-44b3-a2cd-a20aa3259874",
      "metadata": {
        "id": "b1af248e-6069-44b3-a2cd-a20aa3259874"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}